{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of the perceptron using as few libraries as possible"
      ],
      "metadata": {
        "id": "qmHnhafEAZGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "EK6dYoel-NYf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    # Initialize the perceptron model.\n",
        "    # :param input_size: Number of input features\n",
        "    # :param learning_rate: Step size for weight updates\n",
        "    # :param epochs: Number of training iterations\n",
        "    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n",
        "        self.weights = np.zeros(input_size + 1)  # Includes bias term\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "    # Step activation function.\n",
        "    def activation(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    # Predict the output for given input X.\n",
        "    # :param X: Input feature vector\n",
        "    #:return: Predicted class (0 or 1)\n",
        "    def predict(self, X):\n",
        "        net_input = np.dot(X, self.weights[1:]) + self.weights[0]  # Weighted sum + bias\n",
        "        return self.activation(net_input)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      for _ in range(self.epochs):\n",
        "        for xi, target in zip(X, y):\n",
        "          prediction = self.predict(xi)\n",
        "          error = target - prediction\n",
        "          # Update weights and bias\n",
        "          self.weights[1:] += self.learning_rate * error * xi\n",
        "          self.weights[0] += self.learning_rate * error"
      ],
      "metadata": {
        "id": "D_COEkLv-WKN"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # AND gate training data\n",
        "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    y = np.array([0, 0, 0, 1])\n",
        "\n",
        "    # Create and train the perceptron\n",
        "    perceptron = Perceptron(input_size=2)\n",
        "    perceptron.fit(X, y)\n",
        "\n",
        "    # Test the trained model\n",
        "    for sample in X:\n",
        "        print(f\"Input: {sample}, Prediction: {perceptron.predict(sample)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMBqWjaU-aVV",
        "outputId": "09a630b0-319a-4498-c477-9dd08c56c3cc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0 0], Prediction: 0\n",
            "Input: [0 1], Prediction: 0\n",
            "Input: [1 0], Prediction: 0\n",
            "Input: [1 1], Prediction: 1\n"
          ]
        }
      ]
    }
  ]
}