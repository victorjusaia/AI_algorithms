{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Oa_9kEFhnWYy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        #Build the decision tree recursively.\n",
        "\n",
        "        self.tree = self._grow_tree(X, y, depth=0)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth):\n",
        "\n",
        "        #Recursively build the decision tree.\n",
        "\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        # Stopping criteria\n",
        "        if depth >= self.max_depth or num_samples < self.min_samples_split or len(set(y)) == 1:\n",
        "            return Counter(y).most_common(1)[0][0]  # Return most common label\n",
        "\n",
        "        # Find best split\n",
        "        best_feature, best_threshold = self._best_split(X, y)\n",
        "\n",
        "        if best_feature is None:\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        left_mask = X[:, best_feature] < best_threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        left_subtree = self._grow_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_subtree = self._grow_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "\n",
        "        return (best_feature, best_threshold, left_subtree, right_subtree)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "\n",
        "        #Find the best feature and threshold to split on.\n",
        "\n",
        "        best_gain = -1\n",
        "        best_feature, best_threshold = None, None\n",
        "\n",
        "        for feature in range(X.shape[1]):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature] < threshold\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
        "                    continue\n",
        "\n",
        "                gain = self._information_gain(y, y[left_mask], y[right_mask])\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _information_gain(self, y, y_left, y_right):\n",
        "\n",
        "        #Compute information gain.\n",
        "\n",
        "        def entropy(y):\n",
        "            counts = np.bincount(y)\n",
        "            probs = counts / len(y)\n",
        "            return -np.sum([p * np.log2(p) for p in probs if p > 0])\n",
        "\n",
        "        return entropy(y) - (len(y_left) / len(y) * entropy(y_left) + len(y_right) / len(y) * entropy(y_right))\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        #Predict class labels for input samples.\n",
        "\n",
        "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
        "\n",
        "    def _predict_one(self, x, tree):\n",
        "\n",
        "      #Recursively traverses the decision tree to predict a single sample.\n",
        "\n",
        "      if not isinstance(tree, tuple):  # If it's a leaf node, return the class directly\n",
        "        return tree\n",
        "      feature, threshold, left_subtree, right_subtree = tree\n",
        "      if x[feature] < threshold:\n",
        "        return self._predict_one(x, left_subtree)\n",
        "      else:\n",
        "        return self._predict_one(x, right_subtree)"
      ],
      "metadata": {
        "id": "U80PlonMnuGT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "    def __init__(self, n_trees=10, max_depth=None, min_samples_split=2):\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        # Train multiple decision trees on bootstrap samples.\n",
        "\n",
        "        for _ in range(self.n_trees):\n",
        "            indices = np.random.choice(len(X), len(X), replace=True)\n",
        "            X_sample, y_sample = X[indices], y[indices]\n",
        "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        # Predict class labels using majority voting.\n",
        "\n",
        "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        return np.array([Counter(pred).most_common(1)[0][0] for pred in predictions.T])\n",
        "\n",
        "    def evaluate(self, y_true, y_pred):\n",
        "\n",
        "        # Compute accuracy.\n",
        "\n",
        "        accuracy = np.mean(y_true == y_pred)\n",
        "        return {\"accuracy\": accuracy}\n",
        "\n"
      ],
      "metadata": {
        "id": "MyHYijtZnfcc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate synthetic dataset\n",
        "    np.random.seed(42)\n",
        "    X1 = np.random.randn(50, 2) + np.array([2, 2])\n",
        "    X2 = np.random.randn(50, 2) + np.array([-2, -2])\n",
        "    X = np.vstack((X1, X2))\n",
        "    y = np.hstack((np.zeros(50, dtype=int), np.ones(50, dtype=int)))  # Two classes: 0 and 1\n",
        "\n",
        "    model = RandomForest(n_trees=10, max_depth=5)\n",
        "    model.fit(X, y)\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    metrics = model.evaluate(y, predictions)\n",
        "\n",
        "    print(\"Predictions:\", predictions)\n",
        "    print(\"Metrics:\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6jXZGN5osoD",
        "outputId": "6702bd47-e480-448d-c528-f6f83ab6e8a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Metrics: {'accuracy': 1.0}\n"
          ]
        }
      ]
    }
  ]
}