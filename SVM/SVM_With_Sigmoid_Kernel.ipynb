{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of SVM with a sigmoid kernel"
      ],
      "metadata": {
        "id": "CX7sAOmVlb1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "_f2Ux9BngS7_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The formula for the kernel is : $$K(x, y) = \\tanh\\left(\\alpha \\, (\\mathbf{x} \\cdot \\mathbf{y}) + c\\right)$$"
      ],
      "metadata": {
        "id": "vsM0G0Fwlg59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rxLPtC07gMLH"
      },
      "outputs": [],
      "source": [
        "class SVMSigmoid:\n",
        "    def __init__(self, C=1.0, tol=1e-3, max_iter=1000, alpha_coef=0.01, c_coef=0.0):\n",
        "        self.C = C\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.alpha_coef = alpha_coef  # alpha pararameter of the sigmoid kernel\n",
        "        self.c_coef = c_coef          # c parameter of the sigmoid kernel\n",
        "        self.alpha = None\n",
        "        self.b = 0\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "\n",
        "    def kernel(self, x1, x2):\n",
        "        # sigomoid kernel: K(x1, x2) = tanh(alpha_coef * <x1,x2> + c_coef)\n",
        "        return np.tanh(self.alpha_coef * np.dot(x1, x2) + self.c_coef)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.alpha = np.zeros(n_samples)\n",
        "        self.b = 0\n",
        "\n",
        "        passes = 0\n",
        "        while passes < self.max_iter:\n",
        "            num_changed_alphas = 0\n",
        "            for i in range(n_samples):\n",
        "                f_i = np.sum(self.alpha * y * np.array([self.kernel(X[j], X[i]) for j in range(n_samples)])) + self.b\n",
        "                E_i = f_i - y[i]\n",
        "\n",
        "                if ((y[i]*E_i < -self.tol and self.alpha[i] < self.C) or\n",
        "                    (y[i]*E_i > self.tol and self.alpha[i] > 0)):\n",
        "\n",
        "                    j = np.random.choice([x for x in range(n_samples) if x != i])\n",
        "                    f_j = np.sum(self.alpha * y * np.array([self.kernel(X[k], X[j]) for k in range(n_samples)])) + self.b\n",
        "                    E_j = f_j - y[j]\n",
        "\n",
        "                    alpha_i_old, alpha_j_old = self.alpha[i], self.alpha[j]\n",
        "\n",
        "                    if y[i] != y[j]:\n",
        "                        L = max(0, self.alpha[j] - self.alpha[i])\n",
        "                        H = min(self.C, self.C + self.alpha[j] - self.alpha[i])\n",
        "                    else:\n",
        "                        L = max(0, self.alpha[i] + self.alpha[j] - self.C)\n",
        "                        H = min(self.C, self.alpha[i] + self.alpha[j])\n",
        "                    if L == H:\n",
        "                        continue\n",
        "\n",
        "                    K_ii = self.kernel(X[i], X[i])\n",
        "                    K_jj = self.kernel(X[j], X[j])\n",
        "                    K_ij = self.kernel(X[i], X[j])\n",
        "                    eta = 2 * K_ij - K_ii - K_jj\n",
        "                    if eta >= 0:\n",
        "                        continue\n",
        "\n",
        "                    self.alpha[j] = self.alpha[j] - (y[j]*(E_i - E_j)) / eta\n",
        "                    self.alpha[j] = np.clip(self.alpha[j], L, H)\n",
        "\n",
        "                    if abs(self.alpha[j] - alpha_j_old) < 1e-5:\n",
        "                        continue\n",
        "\n",
        "                    self.alpha[i] = self.alpha[i] + y[i]*y[j]*(alpha_j_old - self.alpha[j])\n",
        "\n",
        "                    b1 = self.b - E_i - y[i]*(self.alpha[i]-alpha_i_old)*K_ii - y[j]*(self.alpha[j]-alpha_j_old)*K_ij\n",
        "                    b2 = self.b - E_j - y[i]*(self.alpha[i]-alpha_i_old)*K_ij - y[j]*(self.alpha[j]-alpha_j_old)*K_jj\n",
        "\n",
        "                    if 0 < self.alpha[i] < self.C:\n",
        "                        self.b = b1\n",
        "                    elif 0 < self.alpha[j] < self.C:\n",
        "                        self.b = b2\n",
        "                    else:\n",
        "                        self.b = (b1 + b2) / 2\n",
        "\n",
        "                    num_changed_alphas += 1\n",
        "\n",
        "            if num_changed_alphas == 0:\n",
        "                passes += 1\n",
        "            else:\n",
        "                passes = 0\n",
        "\n",
        "        self.support_vectors_idx = np.where(self.alpha > 1e-5)[0]\n",
        "        self.support_vectors = self.X[self.support_vectors_idx]\n",
        "        self.support_vector_labels = self.y[self.support_vectors_idx]\n",
        "        self.alpha = self.alpha[self.support_vectors_idx]\n",
        "\n",
        "    def project(self, X):\n",
        "        y_predict = np.zeros(X.shape[0])\n",
        "        for i in range(X.shape[0]):\n",
        "            s = 0\n",
        "            for alpha, sv_y, sv in zip(self.alpha, self.support_vector_labels, self.support_vectors):\n",
        "                s += alpha * sv_y * self.kernel(sv, X[i])\n",
        "            y_predict[i] = s\n",
        "        return y_predict + self.b\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.sign(self.project(X))\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "  accuracy = np.mean(y_true == y_pred)\n",
        "  tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "  tn = np.sum((y_true == -1) & (y_pred == -1))\n",
        "  fp = np.sum((y_true == -1) & (y_pred == 1))\n",
        "  fn = np.sum((y_true == 1) & (y_pred == -1))\n",
        "\n",
        "  precision = tp / (tp + fp) if (tp+fp) > 0 else 0\n",
        "  recall = tp / (tp + fn) if (tp+fn) > 0 else 0\n",
        "  f1_score = 2 * precision * recall / (precision + recall) if (precision+recall) > 0 else 0\n",
        "\n",
        "  return accuracy, precision, recall, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Ejemplo simple: datos no linealmente separables con transformaci√≥n sigmoidal\n",
        "    np.random.seed(42)\n",
        "    X1 = np.random.randn(30, 2) + np.array([1, 1])\n",
        "    X2 = np.random.randn(30, 2) + np.array([-1, -1])\n",
        "    X = np.vstack((X1, X2))\n",
        "    y = np.hstack((np.ones(30), -np.ones(30)))\n",
        "\n",
        "    model = SVMSigmoid(C=1.0, alpha_coef=0.1, c_coef=0.0)\n",
        "    model.fit(X, y)\n",
        "    preds = model.predict(X)\n",
        "\n",
        "    accuracy, precision, recall, f1_score = compute_metrics(y, preds)\n",
        "    print(\"Predicciones:\", preds)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScAN7hXsgU3L",
        "outputId": "e69f0e05-b0ea-4bf9-e6fa-d8d104319ad9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones: [ 1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
            " -1. -1.  1. -1. -1.  1.]\n",
            "Accuracy: 0.9000\n",
            "Precision: 0.8529\n",
            "Recall: 0.9667\n",
            "F1 Score: 0.9062\n"
          ]
        }
      ]
    }
  ]
}